{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3.5 (clean)",
      "language": "python",
      "name": "clean3.5"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "archon_dedupe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MlwrB7VvI4P"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import hashlib\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "j2sxoVPlAAnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPlalIPIp8P1"
      },
      "source": [
        "destination_db = \"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/colab-violingan/archon-analysis\" #@param {type:\"string\"}\n",
        "des_datasize = \"if known\" #@param {type:\"string\"}\n",
        "min_size = \"176440\" #@param {type:\"string\"}\n",
        "\n",
        "min_size = int(min_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL\n",
        "# dest_datasize = len(\n",
        "    # [name for name in os.listdir(destination_db) if os.path.isfile(\n",
        "        # os.path.join(destination_db, name))])\n",
        "# NOTE: depending on size of folder, this can error out multiple times - \n",
        "#Colab will cache the results, so retry until success and log the number for future attempts.\n",
        "# print(dest_datasize)"
      ],
      "metadata": {
        "id": "Zo3wJzf7HWeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_reader(fobj, chunk_size=1024):\n",
        "    while True:\n",
        "        chunk = fobj.read(chunk_size)\n",
        "        if not chunk:\n",
        "            return\n",
        "        yield chunk\n",
        "\n",
        "\n",
        "def get_hash(filename, first_chunk_only=False, hash=hashlib.sha1):\n",
        "    hashobj = hash()\n",
        "    file_object = open(filename, 'rb')\n",
        "\n",
        "    if first_chunk_only:\n",
        "        hashobj.update(file_object.read(1024))\n",
        "    else:\n",
        "        for chunk in chunk_reader(file_object):\n",
        "            hashobj.update(chunk)\n",
        "    hashed = hashobj.digest()\n",
        "\n",
        "    file_object.close()\n",
        "    return hashed\n",
        "\n",
        "\n",
        "def check_for_duplicates(path, hash=hashlib.sha1):\n",
        "    hashes_by_size = defaultdict(list)  # dict of size_in_bytes: [full_path_to_file1, full_path_to_file2, ]\n",
        "    hashes_on_1k = defaultdict(list)  # dict of (hash1k, size_in_bytes): [full_path_to_file1, full_path_to_file2, ]\n",
        "    hashes_full = {}   # dict of full_file_hash: full_path_to_file_string\n",
        "    counter = 0\n",
        "\n",
        "\n",
        "    for filename in os.scandir(destination_db):\n",
        "        counter += 1\n",
        "        if (counter % 1000 == 0): print(\"completed \" + str(counter) + \" of \" + str(dest_datasize))\n",
        "        full_path = destination_db + \"/\" + str(filename.name)\n",
        "        file_size = os.path.getsize(full_path)\n",
        "        if (file_size < min_size): \n",
        "          print(\"removing\" + filename)\n",
        "          os.remove(filename)\n",
        "\n",
        "        if (file_size >= min_size): hashes_by_size[file_size].append(full_path)\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for size_in_bytes, files in hashes_by_size.items():\n",
        "\n",
        "        if len(files) < 2:\n",
        "            continue \n",
        "\n",
        "        for filename in files:\n",
        "          counter += 1\n",
        "          if (counter % 1000 == 0): print(\"completed hash for\" + str(counter) + \" of \" + str(len(hashes_by_size)))\n",
        "          small_hash = get_hash(filename, first_chunk_only=True)\n",
        "          hashes_on_1k[(small_hash, size_in_bytes)].append(filename)\n",
        "\n",
        "    for __, files_list in hashes_on_1k.items():\n",
        "        if len(files_list) < 2:\n",
        "            continue\n",
        "\n",
        "        for filename in files_list:\n",
        "            try: \n",
        "                full_hash = get_hash(filename, first_chunk_only=False)\n",
        "                duplicate = hashes_full.get(full_hash)\n",
        "                if duplicate:\n",
        "                    print(\"Duplicate found: {} and {}\".format(filename, duplicate))\n",
        "                    os.remove(filename)\n",
        "                else:\n",
        "                    hashes_full[full_hash] = filename\n",
        "            except (OSError,):\n",
        "                # the file access might've changed till the exec point got here \n",
        "                continue\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "      check_for_duplicates(\"/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/colab-violingan/archon-analysis\")"
      ],
      "metadata": {
        "id": "a0LU7YwKRhip"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}