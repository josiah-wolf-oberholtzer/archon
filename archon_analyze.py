# -*- coding: utf-8 -*-
"""archon_analyze.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A1AEVWbrBRvxWBlDTrvvYClTazBz5ylV
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install librosa==0.8.0
import numpy as np
import json as json
import librosa
import math
import os, os.path

destination_db = "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/colab-violingan/archon-analysis" #@param {type:"string"}
des_datasize = "if known" #@param {type:"string"}
slice_size = "2" #@param {type:"string"}
hop_length = "2048" #@param {type:"string"}
sr = "44100" #@param {type:"string"}
output_filename = "/content/drive/My Drive/analysis.json" #@param {type:"string"}

hop = int(hop_length)
sr = int(sr)
slice_size = int(slice_size)
counter = 0
data = []

dest_datasize = len([name for name in os.listdir(destination_db) if os.path.isfile(os.path.join(destination_db, name))])

counter = 0
data = []
for filename in os.scandir(destination_db):
  if (filename.path.endswith(".wav")):
    y, sr = librosa.load(filename, sr=sr)
    c_buff = []
    f_buff = []
    r_buff = []
    v_buff = []
    p_buff = []
    c_buff.append(
        np.ndarray.flatten(
        librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop)))
    f_buff.append(
        np.ndarray.flatten(
        librosa.feature.spectral_flatness(y=y, hop_length=hop)))
    r_buff.append(
        np.ndarray.flatten(
        librosa.feature.spectral_rolloff(y=y, sr=sr, hop_length=hop)))
    v_buff.append(
        np.ndarray.flatten(
        librosa.feature.rms(y=y, hop_length=hop)))
    p_buff.append(
        np.ndarray.flatten(
        librosa.yin(y,80,10000, hop_length=hop)))
    id = filename.name

    data.append({ 
            "id": id,
            "cent": str(np.median(c_buff)),
            "flat": str(np.median(f_buff)),
            "rolloff": str(np.median(r_buff)),
            "rms": str(np.median(v_buff)),
            "f0": str(librosa.hz_to_note(np.median(p_buff))) 
        })

    counter += 1
    print("completed " + str(counter) + " of " + str(dest_datasize))

data = '''
{
  "sample: " ''' + str(data) + '''
}
'''

savefile = output_filename
with open(savefile, 'a') as outfile:
  json.dump(data, outfile, indent=2)

!mv "/content/analysis.json" ""