# -*- coding: utf-8 -*-
"""archon_analyze.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A1AEVWbrBRvxWBlDTrvvYClTazBz5ylV
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install librosa==0.8.0
import numpy as np
import json as json
import librosa
import os, os.path

destination_db = "/content/drive/My Drive/IRCMS_GAN_collaborative_database/Experiments/colab-violingan/archon-analysis/" #@param {type:"string"}
dest_datasize = "46676" #@param {type:"string"}
slice_size = "2" #@param {type:"string"}
hop_length = "2048" #@param {type:"string"}
sr = "44100" #@param {type:"string"}
output_filename = "/content/drive/My Drive/analysis_f.json" #@param {type:"string"}
analysis_filename = "/content/drive/My Drive/analysis_f.json" #@param {type:"string"}
trial_filename = "/content/drive/My Drive/trial.json" #@param {type:"string"}

hop = int(hop_length)
sr = int(sr)
slice_size = int(slice_size)
dest_datasize = int(dest_datasize)

# OPTIONAL
# dest_datasize = len(
    # [name for name in os.listdir(destination_db) if os.path.isfile(
        # os.path.join(destination_db, name))])
# NOTE: depending on size of folder, this can error out multiple times - 
#Colab will cache the results, so retry until success and log the number for future attempts.
# print(dest_datasize)

## GRAB DESCRIPTORS FROM AUDIODB
def analyze_db(db = destination_db):
  counter = 0
  pcounter = 0
  ncounter = 0

  data = []
  for filename in os.scandir(db):

    if (filename.path.endswith(".wav")):

      y, sr = librosa.load(filename, sr=sr)
    
      id = filename.name

      cent = np.median(
        np.ndarray.flatten(
        librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop)))
      flat = np.median(
        np.ndarray.flatten(
        librosa.feature.spectral_flatness(y=y, hop_length=hop)))
      rolloff = np.median(
        np.ndarray.flatten(
        librosa.feature.spectral_rolloff(y=y, sr=sr, hop_length=hop)))
      rms = np.median(
        np.ndarray.flatten(
        librosa.feature.rms(y=y, hop_length=hop)))
    
      f0, voiced_flag, voiced_probs = librosa.pyin(y,
                                   fmin=librosa.note_to_hz('C2'),
                                   fmax=librosa.note_to_hz('C7'))
    
      voiced = np.median(np.ndarray.flatten(voiced_flag))

      if (voiced == True):
        f0 = f0[~np.isnan(f0)]
        pitch = np.median(np.ndarray.flatten(f0))
        pitch = str(librosa.hz_to_note(pitch))
        pitch = pitch.replace("â™¯", "#") 
        pcounter += 1
      else: 
        pitch = "unpitched"
        ncounter += 1
  
      data.append({
        str(id):
        { 
            "cent": str(cent),
            "flat": str(flat),
            "rolloff": str(rolloff),
            "rms": str(rms),
            "pitch": pitch
        }
    })

      counter += 1
    
      if (counter % 1000 == 0): 
        print("completed " + str(counter) + " of " + str(dest_datasize))
        print ("there are " + str(pcounter) + " pitched elements and " + str(ncounter) + " nonpitched elements.")

    return data

## STORE ANAYLSIS AS JSON
def export_to_json (savefile = output_filename):
  with open(savefile, 'a') as outfile:
    json.dump(data, outfile, indent=2)

## IMPORT JSON FILE
def json_load (filename):
  f = open(filename)
  l = json.load(f)
  return l

def sort_by_pitch (unsort_or_sort, json_file):

  counter = 0 
  pitch = ""
  
  for entry in json_file:

    for k, v in entry.items():
      sample = v
      counter += 1
      print(counter)

      filename = k

      pitch = sample.get("pitch")
      
      if (pitch != "unpitched"): 
        oct = int(pitch[-1])
        pitch = pitch.replace(str(oct), "")  
        
      pitch_dir = destination_db + pitch + "/"   

      if (unsort_or_sort == "sort"):     
        if (os.path.exists(pitch_dir) == False): os.makedirs(pitch_dir)
        os.replace(destination_db + filename, pitch_dir + filename)

      else: 
        os.replace(pitch_dir + filename, destination_db + filename)

## TO ANALYZE DB AND EXPORT TO JSON
analyze_db()
export_to_json()

## TO MOVE FILES BY PITCH INTO SUBDIRECTORIES
d_lib = json_load(output_filename)
sort_by_pitch ("sort", d_lib)